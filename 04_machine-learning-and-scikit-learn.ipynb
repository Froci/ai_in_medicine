{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with scikit-learn\n",
    "\n",
    "Tutors: Jaime Rodríguez-Guerra (jaime.rodriguez@charite.de), Jan Philipp Albrecht (j.p.albrecht@fu-berlin.de)\n",
    "\n",
    "> Based on [previous work](https://github.com/volkamerlab/TeachOpenCADD/blob/master/talktorials/7_machine_learning/T7_machine_learning.ipynb) by Jan Philipp Albrecht and Jacob Gora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Aims of this session\n",
    "\n",
    "Familiarize yourself with the ground concepts of machine learning while you apply popular algorithms and patterns in Python's `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning goals\n",
    "\n",
    "\n",
    "## Theory\n",
    "\n",
    "* Machine Learning (ML) methods\n",
    "* Data preparation\n",
    "\n",
    "## Practical\n",
    "\n",
    "* Prepare your data\n",
    "* Use regression to find correlations between MMSE and hippocampus volume\n",
    "* Apply Random Forests to predict Alzheimer's disease based on volumetric measurements and other variables\n",
    "* Cluster with k-means to guess the thresholds used for MMSE-based diagnosis\n",
    "* Validate your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* ML:\n",
    "    * Random forest (RF): [http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf](http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf)\n",
    "    * Support vector machines (SVM): [https://link.springer.com/article/10.1007%2FBF00994018](https://link.springer.com/article/10.1007%2FBF00994018)\n",
    "    * Artificial neural networks (ANN): [https://www.frontiersin.org/research-topics/4817/artificial-neural-networks-as-models-of-neural-information-processing](https://www.frontiersin.org/research-topics/4817/artificial-neural-networks-as-models-of-neural-information-processing)\n",
    "* Performance: \n",
    "    * [Sensitivity and specificity (Wikipedia)](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)\n",
    "    * [Roc curve and AUC (Wikipedia)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)\n",
    "* See also [this notebook by B. Merget](https://github.com/Team-SKI/Publications/tree/master/Profiling_prediction_of_kinase_inhibitors) from [*J. Med. Chem.*, 2017, 60, 474−485](https://pubs.acs.org/doi/10.1021/acs.jmedchem.6b01611) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "\n",
    "### Supervised vs unsupervised learning\n",
    "\n",
    "In supervised learning, the algorithm is fed data that is well labelled (e.g. classification); e.g. some of the data will be tagged with/as the correct answer. In unsupervised learning, the algorithm infers the labels (e.g. clustering).\n",
    "\n",
    "\n",
    "### Machine Learning (ML)\n",
    "\n",
    "ML can be applied for (see also [scikit-learn page](http://scikit-learn.org/stable/)):\n",
    "\n",
    "* **Classification (supervised)**: Identify to which category an object belongs (Nearest neighbors, Naive Bayes, RF, SVM, ...)\n",
    "* **Regression**: Prediction of a continuous-values attribute associated with an object\n",
    "* **Clustering (unsupervised)**: Automated grouping of similar objects into sets\n",
    "\n",
    "#### Supervised learning\n",
    "\n",
    "Learning algorithm creates rules by finding patterns in the training data. \n",
    "\n",
    "* **Decision trees**: A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.\n",
    "* **Random Forest (RF)**: Multiple decision trees which produce a mean prediction.\n",
    "* **Support Vector Machines (SVM)**: SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces. Classifier based on the idea of maximizing the margin as objective function.  \n",
    "\n",
    " \n",
    "#### Validation strategies\n",
    "\n",
    "All models must be validated before using them!\n",
    "\n",
    "__Train-test split__\n",
    "\n",
    "The data is split _beforehand_ in two sets:\n",
    "\n",
    "* The training set, which will be used to _train_ the model.\n",
    "* The testing set, which will be used to validate the answer provided by the trained model. This data shouldn't have been _seen_ by the model.\n",
    "\n",
    "There are several criteria to split the data into these two sets, but a common one is a random split where 20% of the data goes to the testing set and the remaining 80% goes to the training set. This is called a 80/20 split.\n",
    "\n",
    "__K-fold cross validation__\n",
    "\n",
    "This model validation technique splits the dataset in two groups in an iterative manner:\n",
    "\n",
    "* Training data set: Considered as the known dataset on which the model is trained\n",
    "* Test dataset: Unknown dataset on which the model is then tested\n",
    "* Process is repeated k-times\n",
    "\n",
    "The goal is to test the ability of the model to predict data which it has never seen before in order to flag problems known as over-fitting and to assess the generalization ability of the model.\n",
    "\n",
    "#### Performance measures\n",
    "\n",
    "Having defined a True Positive (TP), True Negative (TN), False Positive (FP) and False Negative (FN), we have:\n",
    "\n",
    "* **Sensitivity**, also true positive rate: TPR = TP/(FN+TP)\n",
    "* **Specificity**, also true negative rate: TNR = TN/(FP + TN)\n",
    "* **Accuracy**, also the trueness: ACC = (TP + TN)/(TP + TN + FP + FN)\n",
    "* **ROC-curve**, receiver operating characteristic curve\n",
    "    * A graphical plot that illustrates the diagnostic ability of our classifier\n",
    "    * Plots the sensitivity against the specificity\n",
    "* **AUC**, the area under the roc curve (AUC):  \n",
    "    * Describes the probability that a classifier will rank a randomly chosen positive instance higher than a negative one\n",
    "    * Values between 0 and 1, the higher the better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "Some algorithms will expect the data in a specific form so, before the models are trained and evaluated, the data needs to be formatted and sanitized accordingly. Perhaps surprisingly, this is often one of the trickiest parts in ML: getting good data and preparing it for the study!\n",
    "\n",
    "Some common tasks include:\n",
    "\n",
    "* Dropping non-numeric values\n",
    "* Cleaning unneeded columns\n",
    "* Standardizing labels and/or magnitudes\n",
    "* Normalizing ranges\n",
    "* Converting measurement units\n",
    "* Finding a good representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions:\n",
    "\n",
    "* Classification: Is MMSE connected to Alzheimer's? MMSE is a 30-question test.\n",
    "* Classification: ADASQ4 would also be nice, but lots of NaN\n",
    "* DX is the simplified version. Use that instead of DX_bl.\n",
    "* Regression: Volumetric measurements, specially in the hippocampus + ventricles can correlate to dementia\n",
    "    * Does the hc volume correlate to questionnaire\n",
    "* Whole brain volumes should NOT correlate\n",
    "* Cluster by sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare your data\n",
    "\n",
    "Before we can use the supplied data, we need to select and transform the parts we are interested in. Then, we will perform a 80/20 split, leaving it ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data as cleaned in day two\n",
    "# df = pd.read_csv(\"../data/alzheimers_disease_reduced.csv\")\n",
    "df = pd.read_csv(\"data/alzheimers_disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14532, 109)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14532 entries, 0 to 14531\n",
      "Columns: 109 entries, RID to update_stamp\n",
      "dtypes: float64(87), int64(5), object(17)\n",
      "memory usage: 12.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>SITE</th>\n",
       "      <th>EXAMDATE</th>\n",
       "      <th>DX_bl</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>WORK</th>\n",
       "      <th>PTETHCAT</th>\n",
       "      <th>...</th>\n",
       "      <th>TAU_bl</th>\n",
       "      <th>PTAU_bl</th>\n",
       "      <th>FDG_bl</th>\n",
       "      <th>PIB_bl</th>\n",
       "      <th>AV45_bl</th>\n",
       "      <th>Years_bl</th>\n",
       "      <th>Month_bl</th>\n",
       "      <th>Month</th>\n",
       "      <th>M</th>\n",
       "      <th>update_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>bl</td>\n",
       "      <td>11</td>\n",
       "      <td>2005-09-08</td>\n",
       "      <td>CN</td>\n",
       "      <td>74.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>16</td>\n",
       "      <td>technical writer and editor</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.36665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-12-04 04:19:56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>bl</td>\n",
       "      <td>11</td>\n",
       "      <td>2005-09-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>81.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Secretary</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>...</td>\n",
       "      <td>239.7</td>\n",
       "      <td>22.83</td>\n",
       "      <td>1.08355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-12-04 04:19:56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>m06</td>\n",
       "      <td>11</td>\n",
       "      <td>2006-03-13</td>\n",
       "      <td>AD</td>\n",
       "      <td>81.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Elementary school teacher</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>...</td>\n",
       "      <td>239.7</td>\n",
       "      <td>22.83</td>\n",
       "      <td>1.08355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.498289</td>\n",
       "      <td>5.96721</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-12-04 04:19:56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>m12</td>\n",
       "      <td>11</td>\n",
       "      <td>2006-09-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>81.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>...</td>\n",
       "      <td>239.7</td>\n",
       "      <td>22.83</td>\n",
       "      <td>1.08355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>11.96720</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2019-12-04 04:19:56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>m24</td>\n",
       "      <td>11</td>\n",
       "      <td>2007-09-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>81.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>...</td>\n",
       "      <td>239.7</td>\n",
       "      <td>22.83</td>\n",
       "      <td>1.08355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.998630</td>\n",
       "      <td>23.93440</td>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2019-12-04 04:19:56.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RID VISCODE  SITE    EXAMDATE DX_bl   AGE PTGENDER  PTEDUCAT  \\\n",
       "0    2      bl    11  2005-09-08    CN  74.3     Male        16   \n",
       "1    3      bl    11  2005-09-12    AD  81.3     Male        18   \n",
       "2    3     m06    11  2006-03-13    AD  81.3     Male        18   \n",
       "3    3     m12    11  2006-09-12    AD  81.3     Male        18   \n",
       "4    3     m24    11  2007-09-12    AD  81.3     Male        18   \n",
       "\n",
       "                          WORK         PTETHCAT  ... TAU_bl PTAU_bl   FDG_bl  \\\n",
       "0  technical writer and editor  Not Hisp/Latino  ...    NaN     NaN  1.36665   \n",
       "1                    Secretary  Not Hisp/Latino  ...  239.7   22.83  1.08355   \n",
       "2    Elementary school teacher  Not Hisp/Latino  ...  239.7   22.83  1.08355   \n",
       "3                Communication  Not Hisp/Latino  ...  239.7   22.83  1.08355   \n",
       "4                   Accounting  Not Hisp/Latino  ...  239.7   22.83  1.08355   \n",
       "\n",
       "   PIB_bl  AV45_bl  Years_bl  Month_bl Month     M           update_stamp  \n",
       "0     NaN      NaN  0.000000   0.00000     0   0.0  2019-12-04 04:19:56.0  \n",
       "1     NaN      NaN  0.000000   0.00000     0   0.0  2019-12-04 04:19:56.0  \n",
       "2     NaN      NaN  0.498289   5.96721     6   6.0  2019-12-04 04:19:56.0  \n",
       "3     NaN      NaN  0.999316  11.96720    12  12.0  2019-12-04 04:19:56.0  \n",
       "4     NaN      NaN  1.998630  23.93440    24  24.0  2019-12-04 04:19:56.0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print some info\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `sklearn`, the naming convention states that:\n",
    "\n",
    "- `X` (uppercase) refers to the dataset containing the known data; e.g. MMSE scores, hippocampus volume\n",
    "- `y` (lowercase) refers to the labels (unknowns) of that data; e.g. diagnosis\n",
    "\n",
    "One of the first tasks you will need to do will be separating the dataframe into the useful parts for each question. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['MMSE']\n",
    "y = df['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running to analyze the data, though, there are some quality check strategies we can consider. One of the easiest to implement is a test-train split; i.e. \"hide\" some of the data from the model as a \"test\" set which we'll use to verify if the predictions are useful outside the training set. One common split is 20% test, 80% train. The library `sklearn` contains an utility function for this precise action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use regression to find correlations between MMSE and hippocampus volume\n",
    "\n",
    "MMSE tests are used to diagnose AD. Low scoring participants are often diagnosed with some kind of cognitive impairment. Some literature references that a reduced hippocampus volume might correlate with some forms of dementia. Would you be able to find a correlation between MMSE scores and hippocampus volume? Let's see if we can find it with linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Random Forests to predict Alzheimer's disease based on volumetric measurements and other variables\n",
    "\n",
    "Literature shows that some volumetric measurements on the brain has been shown to correlate with the development of the disease. Let's check if that's true.\n",
    "\n",
    "The dataset we are using contains information on several volumetric measurements. Namely:\n",
    "\n",
    "- Ventricles\n",
    "- Hippocampus\n",
    "- Entorhinal cortex\n",
    "- Fusiform gyrus\n",
    "\n",
    "Can those be accurate descriptors for AD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster with k-means to guess the thresholds used for MMSE-based diagnosis\n",
    "\n",
    "1. Throw in MMSE, volumetric data (all we have used so far) to a dimensionality reduction algo\n",
    "2. Cluster the PCA/whatever with k-means\n",
    "3. Label the data points and see if they can -see- they five or three groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate your models\n",
    "\n",
    "Now we will compare the models you have defined with the following techniques:\n",
    "\n",
    "* Cross validation\n",
    "* Evaluation matrix: TP, FP, TN, FN\n",
    "* ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Wrap up the talktorial's content here and discuss pros/cons and open questions/challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz\n",
    "\n",
    "Ask three questions that the user should be able to answer after doing this talktorial. Choose important take-aways from this talktorial for your questions.\n",
    "\n",
    "1. Question\n",
    "2. Question\n",
    "3. Question"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "CADDSeminar_2018/CADD_course_talktorial_template.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
