{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with scikit-learn\n",
    "\n",
    "Tutors: Jaime Rodríguez-Guerra (jaime.rodriguez@charite.de), Jan Philipp Albrecht (j.p.albrecht@fu-berlin.de)\n",
    "\n",
    "> Based on [previous work](https://github.com/volkamerlab/TeachOpenCADD/blob/master/talktorials/7_machine_learning/T7_machine_learning.ipynb) by Jan Philipp Albrecht and Jacob Gora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Aims of this session\n",
    "\n",
    "Familiarize yourself with the ground concepts of machine learning while you apply popular algorithms and patterns in Python's `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning goals\n",
    "\n",
    "\n",
    "## Theory\n",
    "\n",
    "* Machine Learning (ML) methods\n",
    "* Data preparation\n",
    "\n",
    "## Practical\n",
    "\n",
    "* Prepare your data\n",
    "* Apply Random Forests to _solve scientific question 1_\n",
    "* Apply Support Vector Machines to _solve scientific question 2_\n",
    "* Apply k-means clustering to _solve scientific question 3_\n",
    "* Validate your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* ML:\n",
    "    * Random forest (RF): [http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf](http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf)\n",
    "    * Support vector machines (SVM): [https://link.springer.com/article/10.1007%2FBF00994018](https://link.springer.com/article/10.1007%2FBF00994018)\n",
    "    * Artificial neural networks (ANN): [https://www.frontiersin.org/research-topics/4817/artificial-neural-networks-as-models-of-neural-information-processing](https://www.frontiersin.org/research-topics/4817/artificial-neural-networks-as-models-of-neural-information-processing)\n",
    "* Performance: \n",
    "    * [Sensitivity and specificity (Wikipedia)](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)\n",
    "    * [Roc curve and AUC (Wikipedia)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)\n",
    "* See also [this notebook by B. Merget](https://github.com/Team-SKI/Publications/tree/master/Profiling_prediction_of_kinase_inhibitors) from [*J. Med. Chem.*, 2017, 60, 474−485](https://pubs.acs.org/doi/10.1021/acs.jmedchem.6b01611) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "\n",
    "### Supervised vs unsupervised learning\n",
    "\n",
    "In supervised learning, the algorithm is fed data that is well labelled (e.g. classification); e.g. some of the data will be tagged with/as the correct answer. In unsupervised learning, the algorithm infers the labels (e.g. clustering).\n",
    "\n",
    "\n",
    "### Machine Learning (ML)\n",
    "\n",
    "ML can be applied for (see also [scikit-learn page](http://scikit-learn.org/stable/)):\n",
    "\n",
    "* **Classification (supervised)**: Identify to which category an object belongs (Nearest neighbors, Naive Bayes, RF, SVM, ...)\n",
    "* **Regression**: Prediction of a continuous-values attribute associated with an object\n",
    "* **Clustering (unsupervised)**: Automated grouping of similar objects into sets\n",
    "\n",
    "#### Supervised learning\n",
    "\n",
    "Learning algorithm creates rules by finding patterns in the training data. \n",
    "\n",
    "* **Decision trees**: A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.\n",
    "* **Random Forest (RF)**: Multiple decision trees which produce a mean prediction.\n",
    "* **Support Vector Machines (SVM)**: SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces. Classifier based on the idea of maximizing the margin as objective function.  \n",
    "\n",
    " \n",
    "#### Validation strategies\n",
    "\n",
    "All models must be validated before using them!\n",
    "\n",
    "__Train-test split__\n",
    "\n",
    "The data is split _beforehand_ in two sets:\n",
    "\n",
    "* The training set, which will be used to _train_ the model.\n",
    "* The testing set, which will be used to validate the answer provided by the trained model. This data shouldn't have been _seen_ by the model.\n",
    "\n",
    "There are several criteria to split the data into these two sets, but a common one is a random split where 20% of the data goes to the testing set and the remaining 80% goes to the training set. This is called a 80/20 split.\n",
    "\n",
    "__K-fold cross validation__\n",
    "\n",
    "This model validation technique splits the dataset in two groups in an iterative manner:\n",
    "\n",
    "* Training data set: Considered as the known dataset on which the model is trained\n",
    "* Test dataset: Unknown dataset on which the model is then tested\n",
    "* Process is repeated k-times\n",
    "\n",
    "The goal is to test the ability of the model to predict data which it has never seen before in order to flag problems known as over-fitting and to assess the generalization ability of the model.\n",
    "\n",
    "#### Performance measures\n",
    "\n",
    "Having defined a True Positive (TP), True Negative (TN), False Positive (FP) and False Negative (FN), we have:\n",
    "\n",
    "* **Sensitivity**, also true positive rate: TPR = TP/(FN+TP)\n",
    "* **Specificity**, also true negative rate: TNR = TN/(FP + TN)\n",
    "* **Accuracy**, also the trueness: ACC = (TP + TN)/(TP + TN + FP + FN)\n",
    "* **ROC-curve**, receiver operating characteristic curve\n",
    "    * A graphical plot that illustrates the diagnostic ability of our classifier\n",
    "    * Plots the sensitivity against the specificity\n",
    "* **AUC**, the area under the roc curve (AUC):  \n",
    "    * Describes the probability that a classifier will rank a randomly chosen positive instance higher than a negative one\n",
    "    * Values between 0 and 1, the higher the better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "Some algorithms will expect the data in a specific form so, before the models are trained and evaluated, the data needs to be formatted and sanitized accordingly. Perhaps surprisingly, this is often one of the trickiest parts in ML: getting good data and preparing it for the study!\n",
    "\n",
    "Some common tasks include:\n",
    "\n",
    "* Dropping non-numeric values\n",
    "* Cleaning unneeded columns\n",
    "* Standardizing labels and/or magnitudes\n",
    "* Normalizing ranges\n",
    "* Converting measurement units\n",
    "* Finding a good representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare your data\n",
    "\n",
    "Before we can use the supplied data, we need to select and transform the parts we are interested in. Then, we will perform a 80/20 split, leaving it ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Random Forests to _solve scientific question 1_\n",
    "\n",
    "Explain what you will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Support Vector Machines to _solve scientific question 2_\n",
    "\n",
    "Explain what you will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply k-means clustering to _solve scientific question 3_\n",
    "\n",
    "Explain what you will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate your models\n",
    "\n",
    "Now we will compare the models you have defined with the following techniques:\n",
    "\n",
    "* Cross validation\n",
    "* Evaluation matrix: TP, FP, TN, FN\n",
    "* ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Wrap up the talktorial's content here and discuss pros/cons and open questions/challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz\n",
    "\n",
    "Ask three questions that the user should be able to answer after doing this talktorial. Choose important take-aways from this talktorial for your questions.\n",
    "\n",
    "1. Question\n",
    "2. Question\n",
    "3. Question"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "CADDSeminar_2018/CADD_course_talktorial_template.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
