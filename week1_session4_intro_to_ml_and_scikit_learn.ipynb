{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI in Medicine <br> Intro to ML and scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:57:00.177842Z",
     "start_time": "2020-06-29T15:57:00.172636Z"
    }
   },
   "source": [
    "***Tutor:*** Konstantine Tsafatinos <br>\n",
    "***Institution:*** Charité - Universitätsmedizin Berlin <br>\n",
    "***Email:*** konstantinos.tsafatinos@bccn-berlin.de <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of this Session:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to introduce you to the basic concepts of machine learning and how to use python and scikit-learn to apply these concepts. By the end of this session, you should be familiar with:\n",
    "\n",
    "- the difference between supervised and unsupervised learning:\n",
    "    - classification vs regression in supervised learning\n",
    "- loading, exploring and preprocessing a dataset; specifically a csv file\n",
    "- how and why we split data into training and test sets\n",
    "- training a model on the training set\n",
    "- evaluating the performance of a model on the test set\n",
    "- using various performance measures to validate a model\n",
    "\n",
    "**note:** see slides for an overview of the first topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python libraries\n",
    "\n",
    "For this session, you will need to make sure the following packages are installed:\n",
    "\n",
    "- numpy\n",
    "- scikit-learn\n",
    "- pandas\n",
    "- matplotlib\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.038053Z",
     "start_time": "2020-07-01T18:19:05.953536Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries for data loading and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# import function for splitting our data \n",
    "from sklearn.model_selection import train_test_split\n",
    "# import model classes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "# import useful functions from the metrics module to evaluate our model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# import lbraries used for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading, Exploration and Preprocessing\n",
    "\n",
    "Here we will introduce two ways of loading your data using numpy and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.215935Z",
     "start_time": "2020-07-01T18:19:07.040395Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "diabetes.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0f24917a118a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load csv into a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetes.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetes.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/bccn/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/bccn/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/bccn/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: diabetes.csv not found."
     ]
    }
   ],
   "source": [
    "# load csv into a numpy array\n",
    "data = np.loadtxt('diabetes.csv', delimiter=',', skiprows=1)\n",
    "data_labels = np.loadtxt('diabetes.csv', dtype=str, delimiter=',', max_rows=1)\n",
    "\n",
    "\n",
    "# load csv into a pandas dataframe\n",
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.227645Z",
     "start_time": "2020-07-01T18:19:05.961Z"
    }
   },
   "outputs": [],
   "source": [
    "# print loaded data to visualize the difference between dataframe and array\n",
    "# visualize the first 5 entries of our dataframe using the head() method.\n",
    "print(df)\n",
    "print(data)\n",
    "print(data_labels)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T02:46:32.235422Z",
     "start_time": "2020-06-30T02:46:32.229427Z"
    }
   },
   "source": [
    "Now that we have loaded the data, we assign variables to our features and labels used to train our model.\n",
    "\n",
    "**NOTE:** We are only going to use the first 100 data points for this tutorial. You will have to follow these steps on the full dataset later.\n",
    "\n",
    "### Using Numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.229829Z",
     "start_time": "2020-07-01T18:19:05.969Z"
    }
   },
   "outputs": [],
   "source": [
    "# separate data into feature vectors and labels\n",
    "x_np, y_np = data[:100, :-1], data[:100, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas\n",
    "\n",
    "Pandas DataFrames allow you to access data in the rows or columns in multiple ways. Two common ways of doing so is using the iloc or loc methods. iloc allows you to index your DataFrame like a np.ndarray using the indices of that array. loc allows you to access your rows and columns using the labels read in from the csv file. If no row labels are specified, pandas will use the indices as the row labels. It is worth noting that when using loc, the start and stop values are both included in the slicing. This is different from the usual python slices that include the starting index but exclude the stopping one. Hence the diffences in how we access rows and columns of our Dataframe using loc and iloc below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.231957Z",
     "start_time": "2020-07-01T18:19:05.985Z"
    }
   },
   "outputs": [],
   "source": [
    "# separate data into feature vectors and labels\n",
    "x_pd, y_pd = df.iloc[:100, :-1], df.iloc[:100, -1]\n",
    "x_pd2, y_pd2 = df.loc[:99, :'Age'], df.loc[:99, 'Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both above examples, we use double assignment to assign values to our variables. Double assignment is a nice way to assign different values to two different variables at the same time. It can help reduce lines in your code.\n",
    "\n",
    "For a sanity check, to make sure that both ways of accessing rows and columns in a DataFrame are equivalent, lets assert the lengths of our features and labels from method 1 and 2 are equal, and then lets print the heads of our feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.234209Z",
     "start_time": "2020-07-01T18:19:05.999Z"
    }
   },
   "outputs": [],
   "source": [
    "# No assertion errors means that the lengths are indeed equal\n",
    "assert len(x_pd) == len(x_pd2)\n",
    "assert len(y_pd) == len(y_pd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.236461Z",
     "start_time": "2020-07-01T18:19:06.011Z"
    }
   },
   "outputs": [],
   "source": [
    "x_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.239242Z",
     "start_time": "2020-07-01T18:19:06.031Z"
    }
   },
   "outputs": [],
   "source": [
    "x_pd2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like both x_pd and x_pd2 are the same :). We will use the pandas implementation moving forward as is has useful class methods we can call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.241441Z",
     "start_time": "2020-07-01T18:19:06.050Z"
    }
   },
   "outputs": [],
   "source": [
    "# use pandas implementation and reassign to x and y\n",
    "x, y = x_pd, y_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data and labels seperated, we an do a little data exploration. It's usually a good idea to visualize the distribution of your labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.243236Z",
     "start_time": "2020-07-01T18:19:06.065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas dataframes has useful class methods like value_counts.\n",
    "y_counts = y.value_counts()\n",
    "n_y = len(y)\n",
    "\n",
    "print('Counts of each value:')\n",
    "print(y_counts)\n",
    "\n",
    "print('\\nPercentage of each class')\n",
    "print(y_counts/n_y*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the values_counts() method, we can print how many of each class we have and calculate their percentages. In our case, since we are using the first 100 entries, they are equivalent. This will change when you use the whole dataset in the exercises.\n",
    "\n",
    "### Seaborn\n",
    "\n",
    "Seaborn has a useful function called countplot() which is convenient for plotting the distribution of our labels. We are also using matplotlib.pyplot to help us label the plot, control its size and save figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.247389Z",
     "start_time": "2020-07-01T18:19:06.084Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the label count plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=y, palette='Purples')\n",
    "plt.title('Label Distribution', fontsize=15);\n",
    "plt.savefig('count_plot');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "Luckily we are using a dataset that is clean, complete, and in the right shape. In practice, you will come across datasets that need to preprocessed before they can be used to train a classifier.\n",
    "Some preprocessing steps include:\n",
    "\n",
    "* Dropping non-numeric values\n",
    "* Cleaning unneeded columns\n",
    "* Standardizing labels and/or magnitudes\n",
    "* Normalizing ranges\n",
    "* Converting measurement units\n",
    "* Finding a good representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Splits\n",
    "\n",
    "Here we want to split out data set into subsets. One used for training and one used to test the model, hence their names. It is important that we evaluate our model on a subset of the data it has never seen before to ensure that we are not overfitting to the data and that our model can generalize well to unseen data.\n",
    "\n",
    "\n",
    "We are going to use 20% of our data as the test set by setting the test_size variable to 0.2. The remainding 80% are used to train the classifer. These ratios may vary depending on the size of the dataset we are using, but 20% to 80% is a good starting point.\n",
    "\n",
    "\n",
    "As a reminder, we are allowed to call the train_test_split function because we imported the function from the sklearn library at the beginning of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.250532Z",
     "start_time": "2020-07-01T18:19:06.091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the features and labels intro training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our Models\n",
    "\n",
    "Now lets instantiate the three models we imported earlier and fit them to our training data. We will be testing out and evaluating the linear support vector classifier, the support vector classifier with an rbf kernel and the logistic regression classifier.\n",
    "\n",
    "### Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.253635Z",
     "start_time": "2020-07-01T18:19:06.096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an object of the model class\n",
    "linsvc = LinearSVC()\n",
    "\n",
    "# fit the model to our train data using a class method\n",
    "linsvc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the warning message from python, it appears as though our linear SVC did not converge. This may imply that our data is not linearly separable and that our other two classifiers might be better suited the for the classification task. Lets forget the linear SVC and try our the other classifiers.\n",
    "\n",
    "### Support Vector Classifier with an RBF Kernel\n",
    "\n",
    "The SVC class kernel defaults to rfb. This is good for separating non-linearly separable data.\n",
    "We set probability to True when instantiating our SVC class in order to get a probability estimate of the labels. SVC uses 5-fold cross-validation internally to compute the probabilities. We will use these probabilities in the evaluation of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.255345Z",
     "start_time": "2020-07-01T18:19:06.101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an object of the model class\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "# fit the model to our train data using a class method\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T15:40:51.331332Z",
     "start_time": "2020-07-01T15:40:51.325150Z"
    }
   },
   "source": [
    "### Logistic Regression Classifier\n",
    "\n",
    "A logistic regression classifier is also good for separating non-linearly separable data. We set the max iterations of our logistic classigier to 200 when we instantiate our class because it did not converges with the default value of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.257076Z",
     "start_time": "2020-07-01T18:19:06.107Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an object of the model class\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "\n",
    "# fit the model to our train data using a class method\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have two model that have been fit to our training data, we can use our test data to evaluate them.\n",
    "\n",
    "## Evaluate our Models\n",
    "\n",
    "\n",
    "### Make predictions\n",
    "\n",
    "We can make predictions on the test set that we will later compare to the respective true labels to evaluate of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.258713Z",
     "start_time": "2020-07-01T18:19:06.116Z"
    }
   },
   "outputs": [],
   "source": [
    "# use the predict() method from our model classes to predict labels given the test set of features x_test.\n",
    "y_pred_svc = svc.predict(x_test)\n",
    "y_pred_log = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Accuracy is a common metric used to evaluate a model. Here we will compute the accuracies of both of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.260091Z",
     "start_time": "2020-07-01T18:19:06.126Z"
    }
   },
   "outputs": [],
   "source": [
    "# we are using the model class method score() to return the accuracy of predictions from each model.\n",
    "print('Accuracy of Support Vector classifier on test set: {:.2f}'.format(svc.score(x_test, y_test)))\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T03:34:11.481994Z",
     "start_time": "2020-07-01T03:34:11.475156Z"
    }
   },
   "source": [
    "Although accuracy is a common metric, it often does not tell the whole story.\n",
    "\n",
    "We need other ways to asses how well our classifier performs.\n",
    "\n",
    "\n",
    "_Successful predictions_ are only one of the possible outcomes of a prediction from a classifier. These outcomes can be generalized using the following four classes:\n",
    "\n",
    "- True positives\n",
    "- False positives\n",
    "- True negatives\n",
    "- False negatives\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"images/confusion_matrix.png\" width=\"500\" height=\"600\"/>\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/confusion_matrix_pregnancy.png\" width=\"500\" height=\"600\"/>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices\n",
    "\n",
    "We can visualize the distribution of prediction classes predicted using a classifier by plotting a confusion matrix. We now use the plot_confusion_matrix function we imported above to visualize the distribtion of True Positives, False Positives, False Negatives, True Negatives for both of our classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.261518Z",
     "start_time": "2020-07-01T18:19:06.137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the documentation to know what variables to use!\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_confusion_matrix(svc, x_test, y_test, normalize='all', ax=plt.subplot(1, 2, 1))\n",
    "plt.title('Confusion Matrix - SVC', fontsize=20);\n",
    "plot_confusion_matrix(logreg, x_test, y_test, normalize='all', ax=plt.subplot(1, 2, 2))\n",
    "plt.title('Confusion Matrix - LR', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T14:11:05.541739Z",
     "start_time": "2020-07-01T14:11:05.536033Z"
    }
   },
   "source": [
    "We can compare the confusion matrices with each other and with the accuracy scores. Be sure to note that the color bars are *not* on the same scale.\n",
    "\n",
    "### Precision, Recall, F$_{1}$-Score and Support\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">\n",
    "            \n",
    "**Variable Definitions**\n",
    "\n",
    "- $tp =$ true positives\n",
    "- $fp =$ false positives\n",
    "- $tn =$ true negatives\n",
    "- $fn =$ false negatives\n",
    "\n",
    "\n",
    "**Precision**\n",
    "\n",
    "$p = \\frac{tp}{tp + fp}$, how precise the model is when classifying a sample as positive. <br><br>\n",
    "It can be thought of as the classifiers ability to **not** misclassify negatives samples.\n",
    "\n",
    "**Recall**\n",
    "\n",
    "$r = \\frac{tp}{tp + fn}$, is a measure of the ability of the classifer to find all positive samples.\n",
    "\n",
    "**F$_{1}$-Score**\n",
    "\n",
    "$\\text{F}_{1} = \\frac{2}{\\text{recall}^{-1} + \\text{ precision}^{-1}} = 2 \\cdot \\\n",
    "\\frac{\\text{recall } \\cdot \\text{ precision}}{\\text{recall } + \\text{ precision}}$, the harmonic mean between precision and recall. <br><br>\n",
    "\n",
    "An F$_{1}$-score reaches its best value at 1; perfect precision and recall.\n",
    "\n",
    "\n",
    "**Support**\n",
    "\n",
    "The support is the number of occurrences of each class in our test set.    \n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/Precisionrecall.svg.png\" width=\"250\" height=\"300\"/>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.262754Z",
     "start_time": "2020-07-01T18:19:06.145Z"
    }
   },
   "outputs": [],
   "source": [
    "# print classification reports for each classifier\n",
    "print('Classification Report for SVC:\\n')\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "print('\\n\\nClassification Report for LR:\\n')\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "The ROC curve is a graph that shows the performance of a classification model at all thresholds. It is a common choice for assessing a binary classifier. The ROC curve is a plot of the True Positive Rate (recall) vs the False Positive Rate. The dotted red line indicates the performance of a random classifier that has a 50% chance of outputting either label. The area under the curve (AUC) of the ROC curve is a measure that tells us how well our classifier can distinguish between the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.264030Z",
     "start_time": "2020-07-01T18:19:06.152Z"
    }
   },
   "outputs": [],
   "source": [
    "# set figure dimensions\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "\n",
    "# compute and plot the AUC and ROC values for the support vector classifier\n",
    "svc_roc_auc = roc_auc_score(y_test, svc.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, svc.predict_proba(x_test)[:,1])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label='SVC - RBF Kernel (area = %0.2f)' % svc_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('SVC_ROC')\n",
    "\n",
    "\n",
    "# compute and plot the AUC and ROC values for the logistic regression classifier\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The behaviour of the ROC curves and the AUC is not very consistent using such a small subset of the data. You will see this behaviour change when implementing it yourself on the full dataset. These plots become more consistent and informative as our dataset increases in size.\n",
    "\n",
    "This is a good basis of metrics you can use to evaluate your models. In practice, you will use n-fold cross-validation and permutation tests to better compare models, tune hyperparameters, and get better estimates for our metrics. This will result in a clearer picture of how the models preform, and which models to use for classification of novel data.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Going through these exercises, you will develope a better undertanding of how to train and test models given a dataset. We suggest that you use the above code as a reference but do **NOT** simply copy and paste. You will gain a deeper understanding if your type the code yourself, implement the functions, and use docs to understand how functions work and what parameters to pass in.\n",
    "\n",
    "### 1. Create new x (features) and y (labels) variables that contain the whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.265247Z",
     "start_time": "2020-07-01T18:19:06.159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hint: There is no need to reload the data. Just reuse the data or df variables that have \n",
    "#       already read in the csv file. We suggest using pandas implementation so you can easily\n",
    "#       the label counts, but either way will work.\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use Seaborn to plot your label counts for the dataset\n",
    "\n",
    "If you have used the pandas, print out the label counts and calculate their percentages. If you have used numpy, calculate and print the counts and percentages by figuring out how many of each class have, and divide the numbers of each class by the total number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.266392Z",
     "start_time": "2020-07-01T18:19:06.166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note: Play around with the plt methods and parameter to see how it changes the \n",
    "#       display of your plots.\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split your data into training and test sets\n",
    "\n",
    "You should use the train_test_split function imported from sklearn. We want you to use a test set size of 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.267771Z",
     "start_time": "2020-07-01T18:19:06.175Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note: Once you have finished all the exercises, vary percent of data used for the test set\n",
    "#       and see how it affects the performance of your models.\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train your Models\n",
    "\n",
    "We saw from before that the linear SVC did not converge. Implement the SCV and Logistic Regression models and them to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.269621Z",
     "start_time": "2020-07-01T18:19:06.180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hint: Remember to compute the probabilities for SVC and make sure that the logistic regression \n",
    "#       model converges.\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate your Models\n",
    "\n",
    "#### a) Predict the labels of the test set using both classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.271330Z",
     "start_time": "2020-07-01T18:19:06.186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hint: Use the predict method from the classifier class\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Compute and print the Accuracy both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.273185Z",
     "start_time": "2020-07-01T18:19:06.192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hint: Use the score method from each model class.\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Plot the confusion matrices from each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.275031Z",
     "start_time": "2020-07-01T18:19:06.198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hint: Use the plot_confusion_matrix function import from sklearn\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Print out the Precision, Recall, F1-Score and Support for both classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.276925Z",
     "start_time": "2020-07-01T18:19:06.204Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hint: Use the classification_report function\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Plot the ROC curves and compute the AUC for both classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T18:19:07.278386Z",
     "start_time": "2020-07-01T18:19:06.210Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hint: Use the roc_auc_score and roc_curve functions\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "380.8px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
