{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# AI in Medicine: Data Science - Basics I\n",
    " \n",
    "## Python Programming: `numpy` and `pandas`\n",
    "\n",
    "- **Instructor**: Dominique Sydow, AG Volkamer, Charité (dominique.sydow@charite.de)\n",
    "- **Target audience**: Medical students from the Charité\n",
    "- **Course date**: February 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aims of this session\n",
    "\n",
    "In this talktorial, you will get in touch with **data science**. Using the **Python packages `numpy` and `pandas`**, you will load and work with the RKI COVID-19 dataset for Berlin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Learning goals\n",
    "\n",
    "### Theory\n",
    "\n",
    "* Data science\n",
    "* The `numpy` library\n",
    "* The `pandas` library\n",
    "\n",
    "### Practical\n",
    "\n",
    "1. Dataset\n",
    "2. Read data with `pandas` as `DataFrame`\n",
    "3. Look at data\n",
    "4. Select columns\n",
    "5. Get unique entries in a column\n",
    "6. Group data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. References\n",
    "\n",
    "- Data science, machine learning, artificial intelligence\n",
    "  - http://varianceexplained.org/r/ds-ml-ai/\n",
    "- Vectors, matrices, tensors\n",
    "  - https://www.quantstart.com/articles/scalars-vectors-matrices-and-tensors-linear-algebra-for-deep-learning-part-1/\n",
    "  - https://dev.to/mmithrakumar/scalars-vectors-matrices-and-tensors-with-tensorflow-2-0-1f66\n",
    "- `numpy`\n",
    "  - https://numpy.org/doc/stable/user/absolute_beginners.html\n",
    "  - https://scipy-lectures.org/intro/numpy/array_object.html\n",
    "- `pandas`\n",
    "  - https://medium.com/dunder-data/how-to-learn-pandas-108905ab4955\n",
    "  - https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/#iloc-selection\n",
    "  - https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c\n",
    "- RKI COVID-19 dataset for Berlin\n",
    "  - https://npgeo-corona-npgeo-de.hub.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0/data?orderBy=Bundesland&where=Bundesland%20%3D%20%27Berlin%27\n",
    "- LaGeSo dataset for Berlin's districts\n",
    "  - https://www.berlin.de/lageso/gesundheit/infektionsepidemiologie-infektionsschutz/corona/tabelle-bezirke/\n",
    "- Dataset on vaccination progress in Germany\n",
    "  - https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Daten/Impfquoten-Tab.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the difference between data science, machine learning, and artificial intelligence? \n",
    "\n",
    "Adapted from [David Robinson's blog post](http://varianceexplained.org/r/ds-ml-ai/).\n",
    "\n",
    "The fields data science, machine learning, and artificial intelligence do have a great deal of **overlap**, but they are **not interchangeable**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data science** produces **insights**\n",
    "  - “The average patient has a 70% chance of survival” (descriptive: describe a dataset)\n",
    "  - “Different patients have different chances of survival” (exploratory: find relationships you did not know about)  \n",
    "  - “A randomized experiment shows that patients assigned to Alice are more likely to survive than those assigned to Bob” (causal: find out what happens to one variable when you make another variable change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Machine learning** (ML) produces **predictions**\n",
    "  - \"Predict whether this patient will go into sepsis”\n",
    "  - “Predict whether this image has a bird in it\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Artificial intelligence** (AI) produces **actions**\n",
    "  - Game-playing algorithms (Deep Blue, AlphaGo)\n",
    "  - Robotics and control theory (motion planning, walking a bipedal robot)\n",
    "  - Optimization (Google Maps choosing a route)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `numpy` library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "\n",
    "* Role: Scientific computing (with arrays)\n",
    "* Website: https://numpy.org/\n",
    "* Description (taken from [here](https://numpy.org/doc/stable/user/absolute_beginners.html)):\n",
    "> NumPy (Numerical Python) is an open source Python library that’s used in almost every field of science and engineering. It’s the universal standard for working with numerical data in Python, and it’s at the core of the scientific Python and PyData ecosystems. NumPy users include everyone from beginning coders to experienced researchers doing state-of-the-art scientific and industrial research and development. The NumPy API is used extensively in Pandas, SciPy, Matplotlib, scikit-learn, scikit-image and most other data science and scientific Python packages.\n",
    "* Documentation: https://numpy.org/devdocs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications\n",
    "\n",
    "- Create vectors (1D), matrices (2D), tensors (>= 3D) in the form of arrays\n",
    "- Use a large collection of high-level mathematical functions to operate on these arrays\n",
    "- Used extensively in `pandas`, `scipy`, `matplotlib`, `scikit-learn` and most other data science and scientific Python packages\n",
    "\n",
    "![](https://res.cloudinary.com/practicaldev/image/fetch/s--oTgfo1EL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/adhiraiyan/DeepLearningWithTF2.0/master/notebooks/figures/fig0201a.png)\n",
    "\n",
    "Figure source: https://dev.to/mmithrakumar/scalars-vectors-matrices-and-tensors-with-tensorflow-2-0-1f66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `pandas` library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "\n",
    "* Role: Data manipulation and analysis\n",
    "* Website: https://pandas.pydata.org/\n",
    "* Description (taken from [here](https://pandas.pydata.org/)):\n",
    "> Pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language. \n",
    "* Documentation: https://pandas.pydata.org/pandas-docs/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications\n",
    "\n",
    "Taken from: https://medium.com/dunder-data/how-to-learn-pandas-108905ab4955\n",
    "\n",
    "> `pandas` is capable of many tasks including:\n",
    ">\n",
    "> * Reading/writing many different data formats\n",
    "> * Selecting subsets of data\n",
    "> * Calculating across rows and down columns\n",
    "> * Finding and filling missing data\n",
    "> * Applying operations to independent groups within the data\n",
    "> * Reshaping data into different forms\n",
    "> * Visualization through matplotlib and seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame` and `Series`\n",
    "\n",
    "The `pandas` library has two main containers of data, the `DataFrame` (2D) and the `Series` (1D). \n",
    "\n",
    "- `DataFrame` [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html):\n",
    "  > Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). Arithmetic operations align on both row and column labels. Can be thought of as a dict-like container for Series objects. The primary pandas data structure\n",
    "- `Series` [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html):\n",
    "  > One-dimensional ndarray with axis labels (including time series).\n",
    "\n",
    "\n",
    "The `DataFrame` is used more than the `Series`, so let’s take a look at its components.\n",
    "\n",
    "![DataFrame anatomy](https://github.com/volkamerlab/ai_in_medicine/raw/update-2021.02/images/dataframe_anatomy.png)\n",
    "\n",
    "Figure source: https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Our aim:</b> We will walk through all functionalities in pandas that we will need to visualize the latest COVID-19 case numbers for Berlin by age group and district. After you have seen how this can be done, you will get the latest data for the German vaccination progress and will plot the time course of first/second vaccinations yourself.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Dataset\n",
    "\n",
    "We will work with the data on COVID-19 cases which is daily published by the Robert-Koch-Institut (RKI) and is visualized very nicely on the RKI COVID-19 Dashboard (https://corona.rki.de). \n",
    "In this notebook we will focus on data for Berlin.\n",
    "\n",
    "The dataset is freely available [here](https://npgeo-corona-npgeo-de.hub.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0) - we saved this file for you in the repository where this notebook comes from:\n",
    "https://github.com/volkamerlab/ai_in_medicine/raw/update-2021.02/data/20210122_COVID19_RKI.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Read data with `pandas` as `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the libraries `numpy` and `pandas` (abbreviated as `np` and `pd` so that we can write shorter code from here on). Libraries are a collection of functionalities that enable you to perform many common tasks without writing the whole code yourself from scratch.\n",
    "\n",
    "For instance, the `pandas` library provides the function `read_csv()` to read a comma-separated values (csv) file into a so-called `DataFrame`.\n",
    "\n",
    "**Tip**: You can check out available functionalities of a library in this Jupyter notebook, by writing the library name followed by a dot and then hitting the tab key. All available functionalities will pop up for you to explore. Since there are a lot of options, you can narrow it down by writing e.g. `read` while the popup windows is up. \n",
    "\n",
    "**Note**: If you are working in in Google Colab you will first have to disable `Automatically trigger code completions` on `Tools` > `Settings` > `Editor` in order to be able to use this feature.\n",
    "\n",
    "See for yourself all the possible file formats that you can read with `pandas`:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.read  # Hit the tab key while your cursor sits after \"pd.read\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we execute (with `Enter`) this cell, we get an `AttributeError` because the module `pandas` does not know `read()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `?` to get a function's docstring, i.e. a description of what the function does and what kind of parameters we can pass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PathLike[str]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRawIOBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextIOBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mobject\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f855c2eb440\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_date_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarn_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfloat_precision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Read a comma-separated values (csv) file into DataFrame.\n",
       "\n",
       "Also supports optionally iterating or breaking of the file\n",
       "into chunks.\n",
       "\n",
       "Additional help can be found in the online docs for\n",
       "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filepath_or_buffer : str, path object or file-like object\n",
       "    Any valid string path is acceptable. The string could be a URL. Valid\n",
       "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
       "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
       "\n",
       "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
       "\n",
       "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
       "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
       "sep : str, default ','\n",
       "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
       "    the separator, but the Python parsing engine can, meaning the latter will\n",
       "    be used and automatically detect the separator by Python's builtin sniffer\n",
       "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
       "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
       "    will also force the use of the Python parsing engine. Note that regex\n",
       "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
       "delimiter : str, default ``None``\n",
       "    Alias for sep.\n",
       "header : int, list of int, default 'infer'\n",
       "    Row number(s) to use as the column names, and the start of the\n",
       "    data.  Default behavior is to infer the column names: if no names\n",
       "    are passed the behavior is identical to ``header=0`` and column\n",
       "    names are inferred from the first line of the file, if column\n",
       "    names are passed explicitly then the behavior is identical to\n",
       "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
       "    replace existing names. The header can be a list of integers that\n",
       "    specify row locations for a multi-index on the columns\n",
       "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
       "    skipped (e.g. 2 in this example is skipped). Note that this\n",
       "    parameter ignores commented lines and empty lines if\n",
       "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
       "    data rather than the first line of the file.\n",
       "names : array-like, optional\n",
       "    List of column names to use. If the file contains a header row,\n",
       "    then you should explicitly pass ``header=0`` to override the column names.\n",
       "    Duplicates in this list are not allowed.\n",
       "index_col : int, str, sequence of int / str, or False, default ``None``\n",
       "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
       "  string name or column index. If a sequence of int / str is given, a\n",
       "  MultiIndex is used.\n",
       "\n",
       "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
       "  column as the index, e.g. when you have a malformed file with delimiters at\n",
       "  the end of each line.\n",
       "usecols : list-like or callable, optional\n",
       "    Return a subset of the columns. If list-like, all elements must either\n",
       "    be positional (i.e. integer indices into the document columns) or strings\n",
       "    that correspond to column names provided either by the user in `names` or\n",
       "    inferred from the document header row(s). For example, a valid list-like\n",
       "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
       "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
       "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
       "    in ``['foo', 'bar']`` order or\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
       "    for ``['bar', 'foo']`` order.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the column\n",
       "    names, returning names where the callable function evaluates to True. An\n",
       "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
       "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
       "    parsing time and lower memory usage.\n",
       "squeeze : bool, default False\n",
       "    If the parsed data only contains one column then return a Series.\n",
       "prefix : str, optional\n",
       "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
       "mangle_dupe_cols : bool, default True\n",
       "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
       "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
       "    are duplicate names in the columns.\n",
       "dtype : Type name or dict of column -> type, optional\n",
       "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
       "    'c': 'Int64'}\n",
       "    Use `str` or `object` together with suitable `na_values` settings\n",
       "    to preserve and not interpret dtype.\n",
       "    If converters are specified, they will be applied INSTEAD\n",
       "    of dtype conversion.\n",
       "engine : {'c', 'python'}, optional\n",
       "    Parser engine to use. The C engine is faster while the python engine is\n",
       "    currently more feature-complete.\n",
       "converters : dict, optional\n",
       "    Dict of functions for converting values in certain columns. Keys can either\n",
       "    be integers or column labels.\n",
       "true_values : list, optional\n",
       "    Values to consider as True.\n",
       "false_values : list, optional\n",
       "    Values to consider as False.\n",
       "skipinitialspace : bool, default False\n",
       "    Skip spaces after delimiter.\n",
       "skiprows : list-like, int or callable, optional\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
       "    at the start of the file.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the row\n",
       "    indices, returning True if the row should be skipped and False otherwise.\n",
       "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
       "skipfooter : int, default 0\n",
       "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
       "nrows : int, optional\n",
       "    Number of rows of file to read. Useful for reading pieces of large files.\n",
       "na_values : scalar, str, list-like, or dict, optional\n",
       "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
       "    per-column NA values.  By default the following values are interpreted as\n",
       "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
       "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
       "    'nan', 'null'.\n",
       "keep_default_na : bool, default True\n",
       "    Whether or not to include the default NaN values when parsing the data.\n",
       "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
       "\n",
       "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
       "      is appended to the default NaN values used for parsing.\n",
       "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
       "      the default NaN values are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
       "      the NaN values specified `na_values` are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
       "      strings will be parsed as NaN.\n",
       "\n",
       "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
       "    `na_values` parameters will be ignored.\n",
       "na_filter : bool, default True\n",
       "    Detect missing value markers (empty strings and the value of na_values). In\n",
       "    data without any NAs, passing na_filter=False can improve the performance\n",
       "    of reading a large file.\n",
       "verbose : bool, default False\n",
       "    Indicate number of NA values placed in non-numeric columns.\n",
       "skip_blank_lines : bool, default True\n",
       "    If True, skip over blank lines rather than interpreting as NaN values.\n",
       "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
       "    The behavior is as follows:\n",
       "\n",
       "    * boolean. If True -> try parsing the index.\n",
       "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
       "      a single date column.\n",
       "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
       "      result 'foo'\n",
       "\n",
       "    If a column or index cannot be represented as an array of datetimes,\n",
       "    say because of an unparsable value or a mixture of timezones, the column\n",
       "    or index will be returned unaltered as an object data type. For\n",
       "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
       "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
       "    specify ``date_parser`` to be a partially-applied\n",
       "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
       "    :ref:`io.csv.mixed_timezones` for more.\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "infer_datetime_format : bool, default False\n",
       "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
       "    format of the datetime strings in the columns, and if it can be inferred,\n",
       "    switch to a faster method of parsing them. In some cases this can increase\n",
       "    the parsing speed by 5-10x.\n",
       "keep_date_col : bool, default False\n",
       "    If True and `parse_dates` specifies combining multiple columns then\n",
       "    keep the original columns.\n",
       "date_parser : function, optional\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by `parse_dates` into a single array\n",
       "    and pass that; and 3) call `date_parser` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
       "    arguments.\n",
       "dayfirst : bool, default False\n",
       "    DD/MM format dates, international and European format.\n",
       "cache_dates : bool, default True\n",
       "    If True, use a cache of unique, converted dates to apply the datetime\n",
       "    conversion. May produce significant speed-up when parsing duplicate\n",
       "    date strings, especially ones with timezone offsets.\n",
       "\n",
       "    .. versionadded:: 0.25.0\n",
       "iterator : bool, default False\n",
       "    Return TextFileReader object for iteration or getting chunks with\n",
       "    ``get_chunk()``.\n",
       "\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "       ``TextFileReader`` is a context manager.\n",
       "chunksize : int, optional\n",
       "    Return TextFileReader object for iteration.\n",
       "    See the `IO Tools docs\n",
       "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
       "    for more information on ``iterator`` and ``chunksize``.\n",
       "\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "       ``TextFileReader`` is a context manager.\n",
       "compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer' and\n",
       "    `filepath_or_buffer` is path-like, then detect compression from the\n",
       "    following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
       "    decompression). If using 'zip', the ZIP file must contain only one data\n",
       "    file to be read in. Set to None for no decompression.\n",
       "thousands : str, optional\n",
       "    Thousands separator.\n",
       "decimal : str, default '.'\n",
       "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
       "lineterminator : str (length 1), optional\n",
       "    Character to break file into lines. Only valid with C parser.\n",
       "quotechar : str (length 1), optional\n",
       "    The character used to denote the start and end of a quoted item. Quoted\n",
       "    items can include the delimiter and it will be ignored.\n",
       "quoting : int or csv.QUOTE_* instance, default 0\n",
       "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
       "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
       "doublequote : bool, default ``True``\n",
       "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
       "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
       "   field as a single ``quotechar`` element.\n",
       "escapechar : str (length 1), optional\n",
       "    One-character string used to escape other characters.\n",
       "comment : str, optional\n",
       "    Indicates remainder of line should not be parsed. If found at the beginning\n",
       "    of a line, the line will be ignored altogether. This parameter must be a\n",
       "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
       "    fully commented lines are ignored by the parameter `header` but not by\n",
       "    `skiprows`. For example, if ``comment='#'``, parsing\n",
       "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
       "    treated as the header.\n",
       "encoding : str, optional\n",
       "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
       "    standard encodings\n",
       "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
       "dialect : str or csv.Dialect, optional\n",
       "    If provided, this parameter will override values (default or not) for the\n",
       "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
       "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
       "    override values, a ParserWarning will be issued. See csv.Dialect\n",
       "    documentation for more details.\n",
       "error_bad_lines : bool, default True\n",
       "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
       "    default cause an exception to be raised, and no DataFrame will be returned.\n",
       "    If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
       "    returned.\n",
       "warn_bad_lines : bool, default True\n",
       "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
       "    \"bad line\" will be output.\n",
       "delim_whitespace : bool, default False\n",
       "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
       "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
       "    is set to True, nothing should be passed in for the ``delimiter``\n",
       "    parameter.\n",
       "low_memory : bool, default True\n",
       "    Internally process the file in chunks, resulting in lower memory use\n",
       "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
       "    types either set False, or specify the type with the `dtype` parameter.\n",
       "    Note that the entire file is read into a single DataFrame regardless,\n",
       "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
       "    (Only valid with C parser).\n",
       "memory_map : bool, default False\n",
       "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
       "    directly onto memory and access the data directly from there. Using this\n",
       "    option can improve performance because there is no longer any I/O overhead.\n",
       "float_precision : str, optional\n",
       "    Specifies which converter the C engine should use for floating-point\n",
       "    values. The options are ``None`` or 'high' for the ordinary converter,\n",
       "    'legacy' for the original lower precision pandas converter, and\n",
       "    'round_trip' for the round-trip converter.\n",
       "\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "storage_options : dict, optional\n",
       "    Extra options that make sense for a particular storage connection, e.g.\n",
       "    host, port, username, password, etc., if using a URL that will\n",
       "    be parsed by ``fsspec``, e.g., starting \"s3://\", \"gcs://\". An error\n",
       "    will be raised if providing this argument with a non-fsspec URL.\n",
       "    See the fsspec and backend storage implementation docs for the set of\n",
       "    allowed keys and values.\n",
       "\n",
       "    .. versionadded:: 1.2\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or TextParser\n",
       "    A comma-separated values (csv) file is returned as two-dimensional\n",
       "    data structure with labeled axes.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
       "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
       "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/miniconda/envs/kissim/lib/python3.8/site-packages/pandas/io/parsers.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the `read_csv()` function ([see docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)) to load the csv file content as `DataFrame` into the variable `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `read_csv` takes paths in your computer, but also Internet URLs!\n",
    "data = pd.read_csv(\"https://github.com/volkamerlab/ai_in_medicine/raw/update-2021.02/data/20210122_COVID19_RKI.csv.zip\", delimiter=',')\n",
    "#data = pd.read_csv(\"data/20210122_COVID19_RKI.csv.zip\", delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at that `DataFrame` in `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Look at data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame` head/tail\n",
    "\n",
    "Let's have a look at the first few rows of the table using the `head()` function ([see docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html)). \n",
    "\n",
    "**Note**: We will use this command a lot to avoid printing large tables in this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>IdBundesland</th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Landkreis</th>\n",
       "      <th>Altersgruppe</th>\n",
       "      <th>Geschlecht</th>\n",
       "      <th>AnzahlFall</th>\n",
       "      <th>AnzahlTodesfall</th>\n",
       "      <th>Meldedatum</th>\n",
       "      <th>IdLandkreis</th>\n",
       "      <th>Datenstand</th>\n",
       "      <th>NeuerFall</th>\n",
       "      <th>NeuerTodesfall</th>\n",
       "      <th>Refdatum</th>\n",
       "      <th>NeuGenesen</th>\n",
       "      <th>AnzahlGenesen</th>\n",
       "      <th>IstErkrankungsbeginn</th>\n",
       "      <th>Altersgruppe2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/11/15 00:00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2020/11/11 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nicht übermittelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "      <td>A15-A34</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/11/14 00:00:00</td>\n",
       "      <td>1002</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2020/11/14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Nicht übermittelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "      <td>A00-A04</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/09/30 00:00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2020/09/30 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Nicht übermittelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/11/18 00:00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2020/11/15 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nicht übermittelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "      <td>A15-A34</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/11/15 00:00:00</td>\n",
       "      <td>1002</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2020/11/07 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nicht übermittelt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ObjectId  IdBundesland          Bundesland     Landkreis Altersgruppe  \\\n",
       "0         1             1  Schleswig-Holstein  SK Flensburg      A35-A59   \n",
       "1         2             1  Schleswig-Holstein       SK Kiel      A15-A34   \n",
       "2         3             1  Schleswig-Holstein  SK Flensburg      A00-A04   \n",
       "3         4             1  Schleswig-Holstein  SK Flensburg      A35-A59   \n",
       "4         5             1  Schleswig-Holstein       SK Kiel      A15-A34   \n",
       "\n",
       "  Geschlecht  AnzahlFall  AnzahlTodesfall           Meldedatum  IdLandkreis  \\\n",
       "0          W           1                0  2020/11/15 00:00:00         1001   \n",
       "1          W           1                0  2020/11/14 00:00:00         1002   \n",
       "2          M           1                0  2020/09/30 00:00:00         1001   \n",
       "3          W           1                0  2020/11/18 00:00:00         1001   \n",
       "4          W           1                0  2020/11/15 00:00:00         1002   \n",
       "\n",
       "              Datenstand  NeuerFall  NeuerTodesfall             Refdatum  \\\n",
       "0  22.01.2021, 00:00 Uhr          0              -9  2020/11/11 00:00:00   \n",
       "1  22.01.2021, 00:00 Uhr          0              -9  2020/11/14 00:00:00   \n",
       "2  22.01.2021, 00:00 Uhr          0              -9  2020/09/30 00:00:00   \n",
       "3  22.01.2021, 00:00 Uhr          0              -9  2020/11/15 00:00:00   \n",
       "4  22.01.2021, 00:00 Uhr          0              -9  2020/11/07 00:00:00   \n",
       "\n",
       "   NeuGenesen  AnzahlGenesen  IstErkrankungsbeginn      Altersgruppe2  \n",
       "0           0              1                     1  Nicht übermittelt  \n",
       "1           0              1                     0  Nicht übermittelt  \n",
       "2           0              1                     0  Nicht übermittelt  \n",
       "3           0              1                     1  Nicht übermittelt  \n",
       "4           0              1                     1  Nicht übermittelt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()  # Shows by default the first 5 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the last few rows of the table using the `tail()` function ([see docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html)). Note that you can pass a number to the `head()` and `tail()` functions to specify how many first/last rows you want to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>IdBundesland</th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Landkreis</th>\n",
       "      <th>Altersgruppe</th>\n",
       "      <th>Geschlecht</th>\n",
       "      <th>AnzahlFall</th>\n",
       "      <th>AnzahlTodesfall</th>\n",
       "      <th>Meldedatum</th>\n",
       "      <th>IdLandkreis</th>\n",
       "      <th>Datenstand</th>\n",
       "      <th>NeuerFall</th>\n",
       "      <th>NeuerTodesfall</th>\n",
       "      <th>Refdatum</th>\n",
       "      <th>NeuGenesen</th>\n",
       "      <th>AnzahlGenesen</th>\n",
       "      <th>IstErkrankungsbeginn</th>\n",
       "      <th>Altersgruppe2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1075685</th>\n",
       "      <td>1075686</td>\n",
       "      <td>16</td>\n",
       "      <td>Thüringen</td>\n",
       "      <td>LK Altenburger Land</td>\n",
       "      <td>A80+</td>\n",
       "      <td>W</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2021/01/21 00:00:00</td>\n",
       "      <td>16077</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>2021/01/21 00:00:00</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nicht übermittelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075686</th>\n",
       "      <td>1075687</td>\n",
       "      <td>16</td>\n",
       "      <td>Thüringen</td>\n",
       "      <td>LK Altenburger Land</td>\n",
       "      <td>unbekannt</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021/01/05 00:00:00</td>\n",
       "      <td>16077</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2021/01/05 00:00:00</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nicht übermittelt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ObjectId  IdBundesland Bundesland            Landkreis Altersgruppe  \\\n",
       "1075685   1075686            16  Thüringen  LK Altenburger Land         A80+   \n",
       "1075686   1075687            16  Thüringen  LK Altenburger Land    unbekannt   \n",
       "\n",
       "        Geschlecht  AnzahlFall  AnzahlTodesfall           Meldedatum  \\\n",
       "1075685          W           4                0  2021/01/21 00:00:00   \n",
       "1075686          W           1                0  2021/01/05 00:00:00   \n",
       "\n",
       "         IdLandkreis             Datenstand  NeuerFall  NeuerTodesfall  \\\n",
       "1075685        16077  22.01.2021, 00:00 Uhr          1              -9   \n",
       "1075686        16077  22.01.2021, 00:00 Uhr          0              -9   \n",
       "\n",
       "                    Refdatum  NeuGenesen  AnzahlGenesen  IstErkrankungsbeginn  \\\n",
       "1075685  2021/01/21 00:00:00          -9              0                     0   \n",
       "1075686  2021/01/05 00:00:00          -9              0                     0   \n",
       "\n",
       "             Altersgruppe2  \n",
       "1075685  Nicht übermittelt  \n",
       "1075686  Nicht übermittelt  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame` dimensionality\n",
    "\n",
    "Let's show the number of columns and rows (= dimensionality/shape) of the table in the form of `(number of rows, number of columns)` using `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1075687, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame` column names\n",
    "\n",
    "We can get a all columns names using `columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ObjectId', 'IdBundesland', 'Bundesland', 'Landkreis', 'Altersgruppe',\n",
       "       'Geschlecht', 'AnzahlFall', 'AnzahlTodesfall', 'Meldedatum',\n",
       "       'IdLandkreis', 'Datenstand', 'NeuerFall', 'NeuerTodesfall', 'Refdatum',\n",
       "       'NeuGenesen', 'AnzahlGenesen', 'IstErkrankungsbeginn', 'Altersgruppe2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list here the meaning of a few criteria (see full list on [RKI COVID-19 data download website](https://www.arcgis.com/home/item.html?id=dd4580c810204019a7b8eb3e0b329dd6)):\n",
    "\n",
    "- `Bundesland`: State name\n",
    "- `Landkreis`: District name\n",
    "- `Altersgruppe`: Age group (6 groups: `0-4`, `5-14`, `15-34`, `35-59`, `60-79`, `80+` and `unbekannt`=unknown)\n",
    "- `Geschlecht`: Gender (`M`=male, `W`=female and `unbekannt`=unknown)\n",
    "- `AnzahlFall`: Number of cases in group\n",
    "- `AnzahlTodesfall`: Number of deaths in group\n",
    "- `AnzahlGenesen`: Number of recoveries cases in group\n",
    "- `Meldedatum`: Date when case was reported to the Gesundheitsamt (you will use this in the next lesson on data visualization with `matplotlib`)\n",
    "- `Datenstand`: Date when data was updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of a `DataFrame` as a list of lists (whereby each list can contain different datatypes) which is shown as a table with metadata such as column and index names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Helen', 20, 'female'], ['Paul', 25, 'male'], ['Kim', 35, 'female']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists = [['Helen', 20, 'female'], ['Paul', 25, 'male'], ['Kim', 35, 'female']]\n",
    "list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Helen</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kim</td>\n",
       "      <td>35</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age  gender\n",
       "0  Helen   20  female\n",
       "1   Paul   25    male\n",
       "2    Kim   35  female"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list_of_lists, columns=['name', 'age', 'gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to stress this point in reverse: It is also possible to transform our `pandas` `DataFrame` back to a 2D `numpy` matrix (a list of lists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 'Schleswig-Holstein', ..., 1, 1, 'Nicht übermittelt'],\n",
       "       [2, 1, 'Schleswig-Holstein', ..., 1, 0, 'Nicht übermittelt'],\n",
       "       [3, 1, 'Schleswig-Holstein', ..., 1, 0, 'Nicht übermittelt'],\n",
       "       ...,\n",
       "       [1075685, 16, 'Thüringen', ..., 0, 0, 'Nicht übermittelt'],\n",
       "       [1075686, 16, 'Thüringen', ..., 0, 0, 'Nicht übermittelt'],\n",
       "       [1075687, 16, 'Thüringen', ..., 0, 0, 'Nicht übermittelt']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Your turn_: Exercises\n",
    "\n",
    "Let's meet in small groups and work on a few exercises. Afterwards, we will discuss them shortly together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1__: Get (a) the first 4 rows and (b) the last 5 rows in `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2__: Get (a) the number of columns and (b) the third column name in `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 3__: Set up a `DataFrame` containing data on 4 countries:\n",
    "- Country name\n",
    "- Your favorite thing about this country\n",
    "- Have you been there already?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Select columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By column name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select some interesting columns! The `DataFrame` is quite large and we are only interested in a subset of the offered criteria. With `pandas`, it is very easy to slice the columns that you want by the following syntax:\n",
    "\n",
    "```python\n",
    "data[list_of_interesting_columns]\n",
    "```\n",
    "\n",
    "The list of column names of interest could look like this:\n",
    "```python\n",
    "list_of_interesting_columns = ['Bundesland', 'Landkreis']\n",
    "```\n",
    "\n",
    "Taking both steps together it looks like this (note the two sets of `[]`, the inner `[]` is part of the list, the outer `[]` is the syntax for `DataFrame` slicing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Landkreis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bundesland     Landkreis\n",
       "0  Schleswig-Holstein  SK Flensburg\n",
       "1  Schleswig-Holstein       SK Kiel\n",
       "2  Schleswig-Holstein  SK Flensburg\n",
       "3  Schleswig-Holstein  SK Flensburg\n",
       "4  Schleswig-Holstein       SK Kiel"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Bundesland', 'Landkreis']].head()  # Note the use of .head() to show only the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's select all columns of interest in this Jupyter notebook and overwrite `data` with this selection.\n",
    "\n",
    "We see in the following that it is possible to write a command over multiple lines to make is easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[\n",
    "    [\n",
    "        'Bundesland', \n",
    "        'Landkreis', \n",
    "        'Altersgruppe', \n",
    "        'Geschlecht', \n",
    "        'AnzahlFall', \n",
    "        'AnzahlTodesfall', \n",
    "        'AnzahlGenesen', \n",
    "        'Datenstand'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Landkreis</th>\n",
       "      <th>Altersgruppe</th>\n",
       "      <th>Geschlecht</th>\n",
       "      <th>AnzahlFall</th>\n",
       "      <th>AnzahlTodesfall</th>\n",
       "      <th>AnzahlGenesen</th>\n",
       "      <th>Datenstand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "      <td>A15-A34</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "      <td>A00-A04</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "      <td>A15-A34</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bundesland     Landkreis Altersgruppe Geschlecht  AnzahlFall  \\\n",
       "0  Schleswig-Holstein  SK Flensburg      A35-A59          W           1   \n",
       "1  Schleswig-Holstein       SK Kiel      A15-A34          W           1   \n",
       "2  Schleswig-Holstein  SK Flensburg      A00-A04          M           1   \n",
       "3  Schleswig-Holstein  SK Flensburg      A35-A59          W           1   \n",
       "4  Schleswig-Holstein       SK Kiel      A15-A34          W           1   \n",
       "\n",
       "   AnzahlTodesfall  AnzahlGenesen             Datenstand  \n",
       "0                0              1  22.01.2021, 00:00 Uhr  \n",
       "1                0              1  22.01.2021, 00:00 Uhr  \n",
       "2                0              1  22.01.2021, 00:00 Uhr  \n",
       "3                0              1  22.01.2021, 00:00 Uhr  \n",
       "4                0              1  22.01.2021, 00:00 Uhr  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By column AND index names/indices using `loc/iloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Recap__\n",
    "\n",
    "So far we sliced columns using column names like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Landkreis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bundesland     Landkreis\n",
       "0  Schleswig-Holstein  SK Flensburg\n",
       "1  Schleswig-Holstein       SK Kiel\n",
       "2  Schleswig-Holstein  SK Flensburg\n",
       "3  Schleswig-Holstein  SK Flensburg\n",
       "4  Schleswig-Holstein       SK Kiel"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Bundesland', 'Landkreis']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __`loc`__\n",
    "\n",
    "The above code is a shorter form for using `loc`:\n",
    "```python\n",
    "dataframe.loc[list_of_row_names, list_of_column_names]\n",
    "```\n",
    "`index_names` or `column_names` can be set to `:` if we want to select the full row or column, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Landkreis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bundesland     Landkreis\n",
       "0  Schleswig-Holstein  SK Flensburg\n",
       "1  Schleswig-Holstein       SK Kiel\n",
       "2  Schleswig-Holstein  SK Flensburg\n",
       "3  Schleswig-Holstein  SK Flensburg\n",
       "4  Schleswig-Holstein       SK Kiel"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:, ['Bundesland', 'Landkreis']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __`iloc`__\n",
    "\n",
    "Or, instead of row and column names, we can use their indices (like you learnt on day 1 where you selected elements from a list). \n",
    "\n",
    "```python\n",
    "dataframe.iloc[list_of_row_indices, list_of_column_indices].head()\n",
    "```\n",
    "\n",
    "Remember, in Python indices are 0-indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bundesland', 'Landkreis', 'Altersgruppe', 'Geschlecht', 'AnzahlFall',\n",
       "       'AnzahlTodesfall', 'AnzahlGenesen', 'Datenstand'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out index of columns of interest\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altersgruppe</th>\n",
       "      <th>Geschlecht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A15-A34</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00-A04</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A15-A34</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altersgruppe Geschlecht\n",
       "0      A35-A59          W\n",
       "1      A15-A34          W\n",
       "2      A00-A04          M\n",
       "3      A35-A59          W\n",
       "4      A15-A34          W"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:, [2, 3]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: You will use `loc/iloc` in the notebooks to come in the next lessons, but for this lesson here, we will use column selection by column names as discussed first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Landkreis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>SK Kiel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bundesland     Landkreis\n",
       "0  Schleswig-Holstein  SK Flensburg\n",
       "1  Schleswig-Holstein       SK Kiel\n",
       "2  Schleswig-Holstein  SK Flensburg\n",
       "3  Schleswig-Holstein  SK Flensburg\n",
       "4  Schleswig-Holstein       SK Kiel"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Bundesland', 'Landkreis']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Your turn_: Exercises\n",
    "\n",
    "Let's meet in small groups and work on a few exercises. Afterwards, we will discuss them shortly together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 4__: Select the columns listing the number of cases, deaths and recoveries using their __column names__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 5__: Do the same as in Exercise 4 but this time use __`loc`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 6__: Do the same as in Exercise 4 and 5 but this time use __`iloc`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Get unique entries in a column\n",
    "\n",
    "Now, we'd like to check what kind of entries we can find in a column. \n",
    "\n",
    "First, we select a column, similar to how we learned it in *Chapter 5.4*. Since we select this time only **one** column, we do not pass the column name as a list but as a simple string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Schleswig-Holstein\n",
       "1    Schleswig-Holstein\n",
       "2    Schleswig-Holstein\n",
       "3    Schleswig-Holstein\n",
       "4    Schleswig-Holstein\n",
       "Name: Bundesland, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Bundesland'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a `Series` (instead of a `DataFrame`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['Bundesland'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply the `unique()` function ([see docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html)) and check the states in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Schleswig-Holstein', 'Hamburg', 'Niedersachsen', 'Bremen',\n",
       "       'Nordrhein-Westfalen', 'Hessen', 'Rheinland-Pfalz',\n",
       "       'Baden-Württemberg', 'Bayern', 'Saarland', 'Berlin', 'Brandenburg',\n",
       "       'Mecklenburg-Vorpommern', 'Sachsen', 'Sachsen-Anhalt', 'Thüringen'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Bundesland'].unique()  # Note: Here we pass the single column as string not as list (as shown in Chapter 5.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 16 states, let's check with Python's built-in function `len` ([see docs](https://docs.python.org/3/library/functions.html#len)) that returns the length of e.g. list-like objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['Bundesland'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example: Check the date of data update (`'Datenstand'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['22.01.2021, 00:00 Uhr'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Datenstand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Your turn_: Exercises\n",
    "\n",
    "Let's meet in small groups and work on a few exercises. Afterwards, we will discuss them shortly together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 7__: Select the column on age groups (`'Altersgruppe'`) - which age groups are monitored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 8__: Select the column on districts (`'Landkreis'`) - how many districts are monitored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6. Select rows (by conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often, you not only have more criteria (columns) in your dataset than you are actually interested in but also more data points (rows) than you need. Let's say for instance, that we are mainly interested in data points regarding Berlin. Since we have a dataset for Germany, we will need to do some (row) filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select only the state column (`Bundesland`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Schleswig-Holstein\n",
       "1          Schleswig-Holstein\n",
       "2          Schleswig-Holstein\n",
       "3          Schleswig-Holstein\n",
       "4          Schleswig-Holstein\n",
       "                  ...        \n",
       "1075682             Thüringen\n",
       "1075683             Thüringen\n",
       "1075684             Thüringen\n",
       "1075685             Thüringen\n",
       "1075686             Thüringen\n",
       "Name: Bundesland, Length: 1075687, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Bundesland']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `Series` it is very easy to check for each row if it fullfils a given condition. As an example, let's ask for \"Thüringen\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          False\n",
       "1          False\n",
       "2          False\n",
       "3          False\n",
       "4          False\n",
       "           ...  \n",
       "1075682     True\n",
       "1075683     True\n",
       "1075684     True\n",
       "1075685     True\n",
       "1075686     True\n",
       "Name: Bundesland, Length: 1075687, dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Bundesland'] == 'Thüringen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see, that this operation returns a `Series` of the same length and index as our initial `Series` containing boolean values (`True` or `False`).\n",
    "\n",
    "How can we use this boolean Series know to subset `data` for data points concerning Berlin (i.e. filter `data` for rows concerning Berlin)? We use the following syntax:\n",
    "\n",
    "```python\n",
    "# Use one condition\n",
    "data[condition]\n",
    "\n",
    "# Use multipe conditions\n",
    "data[condition1 & condition2]  # Fullfill condition 1 AND 2\n",
    "data[condition1 & not condition2]  # Fullfill condition 1 AND not 2\n",
    "data[condition1 | condition2]  # Fullfill condition 1 OR 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Landkreis</th>\n",
       "      <th>Altersgruppe</th>\n",
       "      <th>Geschlecht</th>\n",
       "      <th>AnzahlFall</th>\n",
       "      <th>AnzahlTodesfall</th>\n",
       "      <th>AnzahlGenesen</th>\n",
       "      <th>Datenstand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>845000</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>SK Berlin Mitte</td>\n",
       "      <td>A00-A04</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845002</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>SK Berlin Mitte</td>\n",
       "      <td>A00-A04</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845004</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>SK Berlin Mitte</td>\n",
       "      <td>A00-A04</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845006</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>SK Berlin Mitte</td>\n",
       "      <td>A00-A04</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845008</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>SK Berlin Mitte</td>\n",
       "      <td>A00-A04</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902495</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>SK Berlin Reinickendorf</td>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902496</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>SK Berlin Reinickendorf</td>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902497</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>SK Berlin Reinickendorf</td>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902498</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>SK Berlin Reinickendorf</td>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902499</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>SK Berlin Reinickendorf</td>\n",
       "      <td>A35-A59</td>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.01.2021, 00:00 Uhr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54898 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bundesland                Landkreis Altersgruppe Geschlecht  \\\n",
       "845000     Berlin          SK Berlin Mitte      A00-A04          W   \n",
       "845002     Berlin          SK Berlin Mitte      A00-A04          W   \n",
       "845004     Berlin          SK Berlin Mitte      A00-A04          W   \n",
       "845006     Berlin          SK Berlin Mitte      A00-A04          W   \n",
       "845008     Berlin          SK Berlin Mitte      A00-A04          W   \n",
       "...           ...                      ...          ...        ...   \n",
       "902495     Berlin  SK Berlin Reinickendorf      A35-A59          W   \n",
       "902496     Berlin  SK Berlin Reinickendorf      A35-A59          W   \n",
       "902497     Berlin  SK Berlin Reinickendorf      A35-A59          W   \n",
       "902498     Berlin  SK Berlin Reinickendorf      A35-A59          W   \n",
       "902499     Berlin  SK Berlin Reinickendorf      A35-A59          W   \n",
       "\n",
       "        AnzahlFall  AnzahlTodesfall  AnzahlGenesen             Datenstand  \n",
       "845000           2                0              2  22.01.2021, 00:00 Uhr  \n",
       "845002           1                0              1  22.01.2021, 00:00 Uhr  \n",
       "845004           1                0              1  22.01.2021, 00:00 Uhr  \n",
       "845006           2                0              2  22.01.2021, 00:00 Uhr  \n",
       "845008           1                0              1  22.01.2021, 00:00 Uhr  \n",
       "...            ...              ...            ...                    ...  \n",
       "902495           5                0              5  22.01.2021, 00:00 Uhr  \n",
       "902496           1                0              1  22.01.2021, 00:00 Uhr  \n",
       "902497           1                0              1  22.01.2021, 00:00 Uhr  \n",
       "902498           3                0              3  22.01.2021, 00:00 Uhr  \n",
       "902499           3                0              3  22.01.2021, 00:00 Uhr  \n",
       "\n",
       "[54898 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Condition\n",
    "state_is_berlin = data['Bundesland'] == 'Berlin'\n",
    "\n",
    "# Subset dataset by condition\n",
    "data[state_is_berlin]  # equals\n",
    "data[data['Bundesland'] == 'Berlin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Your turn_: Exercises\n",
    "\n",
    "Let's meet in small groups and work on a few exercises. Afterwards, we will discuss them shortly together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 9__: Select only data points for Berlin Mitte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 10__: Select only data points for Berlin and patients between 35 and 59 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6. Group data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, we will continue to work only with data for Berlin, so we will save the subset to the new variable `data_berlin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54898, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_berlin = data[data['Bundesland'] == 'Berlin']\n",
    "data_berlin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html:\n",
    "\n",
    "> By `groupby()` we are referring to a process involving one or more of the following steps:\n",
    "> * **Splitting** the data into groups based on some criteria.\n",
    "> * **Applying** a function to each group independently.\n",
    "> * **Combining** the results into a data structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Get group size with `size()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting**: Split data into groups based on a criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f84e1e9ca30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_berlin.groupby('Altersgruppe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.groupby.generic.DataFrameGroupBy"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_berlin.groupby('Altersgruppe'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying and combining**: Apply function to each group, e.g. get the number of entries in each group using `size()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Altersgruppe\n",
       "A00-A04       1598\n",
       "A05-A14       4238\n",
       "A15-A34      17298\n",
       "A35-A59      18393\n",
       "A60-A79       8358\n",
       "A80+          4526\n",
       "unbekannt      487\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_berlin.groupby('Altersgruppe').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is combined into a data structure, i.e. `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_berlin.groupby('Altersgruppe').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `pandas` it is very easy to quickly plot data using the `plot()` function ([see docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html)) - with the parameter `kind` you can specify what plot type you want to plot (in our case we want a barplot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Number of entries in RKI COVID dataset from 22.01.2021, 00:00 Uhr'}, xlabel='Altersgruppe'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_berlin.groupby('Altersgruppe').size().plot(\n",
    "    kind='bar', \n",
    "    title=f'Number of entries in RKI COVID dataset from {data[\"Datenstand\"].unique()[0]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Get group sum with `sum()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the sum of current cases, deaths, and recoveries. \n",
    "\n",
    "The columns needed have the following names:\n",
    "\n",
    "- `AnzahlFall`: Number of cases in group\n",
    "- `AnzahlTodesfall`: Number of deaths in group\n",
    "- `AnzahlGenesen`: Number of recoveries in group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of current COVID-19 cases in Berlin:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115476"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total number of current COVID-19 cases in Berlin:')\n",
    "data_berlin['AnzahlFall'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of COVID-19 associated cases in Berlin:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1995"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total number of COVID-19 associated cases in Berlin:')\n",
    "data_berlin['AnzahlTodesfall'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of COVID-19 recoveries in Berlin:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99675"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total number of COVID-19 recoveries in Berlin:')\n",
    "data_berlin['AnzahlGenesen'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of current COVID-19 cases by Berlin's districts and compare your findings to the official COVID-19 table for Berlin: \n",
    "\n",
    "https://www.berlin.de/lageso/gesundheit/infektionsepidemiologie-infektionsschutz/corona/tabelle-bezirke/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Landkreis\n",
       "SK Berlin Charlottenburg-Wilmersdorf     9865\n",
       "SK Berlin Friedrichshain-Kreuzberg      10063\n",
       "SK Berlin Lichtenberg                    6790\n",
       "SK Berlin Marzahn-Hellersdorf            6298\n",
       "SK Berlin Mitte                         14825\n",
       "SK Berlin Neukölln                      13909\n",
       "SK Berlin Pankow                         9759\n",
       "SK Berlin Reinickendorf                  8983\n",
       "SK Berlin Spandau                        8722\n",
       "SK Berlin Steglitz-Zehlendorf            8504\n",
       "SK Berlin Tempelhof-Schöneberg          11772\n",
       "SK Berlin Treptow-Köpenick               5986\n",
       "Name: AnzahlFall, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_berlin.groupby('Landkreis')['AnzahlFall'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Your turn_: Exercises\n",
    "\n",
    "Let's meet in small groups and work on a few exercises. Afterwards, we will discuss them shortly together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 11__: Since the `groupby` functionality is very powerful but also at first difficult to wraps our head around, go through the first two examples above again in your group and discuss questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 12__: Get the number of COVID-19 recoveries in Berlin grouped by Berlin's districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 13__: Plot the number of current COVID-19 cases in Berlin grouped by Berlin's districts (barplot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discussion\n",
    "\n",
    "In this notebook, we saw how quickly possible it is to read in a csv file as `DataFrame` (*Chapter 5.2*) and to start working with it. \n",
    "- We got a first impression on our COVID-19 Berlin dataset. We looked at the number of data points (`DataFrame` rows) and criteria (`DataFrame` columns) as well as some example data points, see *Chapter 5.3*.\n",
    "- We selected interesting columns and checked what kind of column entries we can except, see *Chapter 5.4 and 5.5*. \n",
    "- We grouped data by certain criteria (columns), and applied operations on these groups, e.g. we counted the number of group entries or got the sum within each group). We also did some first steps towards plotting with `pandas`, see *Chapter 5.6*. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final exercise\n",
    "\n",
    "As promised at the beginning, you will get your own dataset now :)\n",
    "\n",
    "Last year during the course, we could only work with COVID-19 cases data but luckily, this year, we have something happy to look at as well - the vaccination progress in Germany! You can find that data online again at the [RKI website](https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Daten/Impfquoten-Tab.html). We saved this file for you in the repository where this notebook comes from:\n",
    "https://github.com/volkamerlab/ai_in_medicine/raw/update-2021.02/data/20210122_Impfquotenmonitoring_RKI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Erstimpfung</th>\n",
       "      <th>Zweitimpfung</th>\n",
       "      <th>Gesamtzahl verabreichter Impfstoffdosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-27 00:00:00</td>\n",
       "      <td>24249.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-28 00:00:00</td>\n",
       "      <td>19644.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-29 00:00:00</td>\n",
       "      <td>42921.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-30 00:00:00</td>\n",
       "      <td>57370.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-31 00:00:00</td>\n",
       "      <td>37912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37912.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>30581.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-02 00:00:00</td>\n",
       "      <td>44884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-03 00:00:00</td>\n",
       "      <td>24545.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-04 00:00:00</td>\n",
       "      <td>48597.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-05 00:00:00</td>\n",
       "      <td>50903.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-01-06 00:00:00</td>\n",
       "      <td>56083.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-01-07 00:00:00</td>\n",
       "      <td>57426.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-01-08 00:00:00</td>\n",
       "      <td>57853.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-01-09 00:00:00</td>\n",
       "      <td>53451.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-01-10 00:00:00</td>\n",
       "      <td>32198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-01-11 00:00:00</td>\n",
       "      <td>65629.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-01-12 00:00:00</td>\n",
       "      <td>79980.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-01-13 00:00:00</td>\n",
       "      <td>93763.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-01-14 00:00:00</td>\n",
       "      <td>99341.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>99386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-01-15 00:00:00</td>\n",
       "      <td>89032.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>89250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-01-16 00:00:00</td>\n",
       "      <td>54375.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>54673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-01-17 00:00:00</td>\n",
       "      <td>30240.0</td>\n",
       "      <td>11182.0</td>\n",
       "      <td>41422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-01-18 00:00:00</td>\n",
       "      <td>51565.0</td>\n",
       "      <td>13295.0</td>\n",
       "      <td>64860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-01-19 00:00:00</td>\n",
       "      <td>56772.0</td>\n",
       "      <td>20400.0</td>\n",
       "      <td>77172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-01-20 00:00:00</td>\n",
       "      <td>64777.0</td>\n",
       "      <td>32164.0</td>\n",
       "      <td>96941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-01-21 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-01-22 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-01-23 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-01-24 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-01-25 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-01-27 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-01-28 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-01-29 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-01-30 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2021-01-31 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gesamt</td>\n",
       "      <td>1324091.0</td>\n",
       "      <td>77602.0</td>\n",
       "      <td>1401693.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Datum  Erstimpfung  Zweitimpfung  \\\n",
       "0   2020-12-27 00:00:00      24249.0           0.0   \n",
       "1   2020-12-28 00:00:00      19644.0           0.0   \n",
       "2   2020-12-29 00:00:00      42921.0           0.0   \n",
       "3   2020-12-30 00:00:00      57370.0           0.0   \n",
       "4   2020-12-31 00:00:00      37912.0           0.0   \n",
       "5   2021-01-01 00:00:00      30581.0           0.0   \n",
       "6   2021-01-02 00:00:00      44884.0           0.0   \n",
       "7   2021-01-03 00:00:00      24545.0           0.0   \n",
       "8   2021-01-04 00:00:00      48597.0           0.0   \n",
       "9   2021-01-05 00:00:00      50903.0           0.0   \n",
       "10  2021-01-06 00:00:00      56083.0           0.0   \n",
       "11  2021-01-07 00:00:00      57426.0           0.0   \n",
       "12  2021-01-08 00:00:00      57853.0           0.0   \n",
       "13  2021-01-09 00:00:00      53451.0           0.0   \n",
       "14  2021-01-10 00:00:00      32198.0           0.0   \n",
       "15  2021-01-11 00:00:00      65629.0           0.0   \n",
       "16  2021-01-12 00:00:00      79980.0           0.0   \n",
       "17  2021-01-13 00:00:00      93763.0           0.0   \n",
       "18  2021-01-14 00:00:00      99341.0          45.0   \n",
       "19  2021-01-15 00:00:00      89032.0         218.0   \n",
       "20  2021-01-16 00:00:00      54375.0         298.0   \n",
       "21  2021-01-17 00:00:00      30240.0       11182.0   \n",
       "22  2021-01-18 00:00:00      51565.0       13295.0   \n",
       "23  2021-01-19 00:00:00      56772.0       20400.0   \n",
       "24  2021-01-20 00:00:00      64777.0       32164.0   \n",
       "25  2021-01-21 00:00:00          0.0           0.0   \n",
       "26  2021-01-22 00:00:00          0.0           0.0   \n",
       "27  2021-01-23 00:00:00          0.0           0.0   \n",
       "28  2021-01-24 00:00:00          0.0           0.0   \n",
       "29  2021-01-25 00:00:00          0.0           0.0   \n",
       "30  2021-01-26 00:00:00          0.0           0.0   \n",
       "31  2021-01-27 00:00:00          0.0           0.0   \n",
       "32  2021-01-28 00:00:00          0.0           0.0   \n",
       "33  2021-01-29 00:00:00          0.0           0.0   \n",
       "34  2021-01-30 00:00:00          0.0           0.0   \n",
       "35  2021-01-31 00:00:00          0.0           0.0   \n",
       "36                 None          NaN           NaN   \n",
       "37               Gesamt    1324091.0       77602.0   \n",
       "\n",
       "    Gesamtzahl verabreichter Impfstoffdosen  \n",
       "0                                   24249.0  \n",
       "1                                   19644.0  \n",
       "2                                   42921.0  \n",
       "3                                   57370.0  \n",
       "4                                   37912.0  \n",
       "5                                   30581.0  \n",
       "6                                   44884.0  \n",
       "7                                   24545.0  \n",
       "8                                   48597.0  \n",
       "9                                   50903.0  \n",
       "10                                  56083.0  \n",
       "11                                  57426.0  \n",
       "12                                  57853.0  \n",
       "13                                  53451.0  \n",
       "14                                  32198.0  \n",
       "15                                  65629.0  \n",
       "16                                  79980.0  \n",
       "17                                  93763.0  \n",
       "18                                  99386.0  \n",
       "19                                  89250.0  \n",
       "20                                  54673.0  \n",
       "21                                  41422.0  \n",
       "22                                  64860.0  \n",
       "23                                  77172.0  \n",
       "24                                  96941.0  \n",
       "25                                      0.0  \n",
       "26                                      0.0  \n",
       "27                                      0.0  \n",
       "28                                      0.0  \n",
       "29                                      0.0  \n",
       "30                                      0.0  \n",
       "31                                      0.0  \n",
       "32                                      0.0  \n",
       "33                                      0.0  \n",
       "34                                      0.0  \n",
       "35                                      0.0  \n",
       "36                                      NaN  \n",
       "37                                1401693.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination_monitoring = pd.read_excel(\"https://github.com/volkamerlab/ai_in_medicine/raw/update-2021.02/data/20210122_Impfquotenmonitoring_RKI.xlsx\", sheet_name=\"Impfungen_proTag\")\n",
    "#vaccination_monitoring = pd.read_excel(\"data/20210122_Impfquotenmonitoring_RKI.xlsx\", sheet_name=\"Impfungen_proTag\")\n",
    "vaccination_monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only rows that you need for the vaccination time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the date as the `DataFrame` index. Use `pandas.DataFrame.set_index(column_name)` for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pd.DataFrame.cumsum()` to generate a DataFrame with cummulutive data and plot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solutions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A word of encouragement :)__ \n",
    "\n",
    "Before you take a look at the solutions, try to solve the exercises yourself. \n",
    "\n",
    "All the information needed lives in _5. Practical_ - if you are stuck, first take a look at the material there. Talk to your fellow students. If you have a solution, then go ahead and take a look here.\n",
    "\n",
    "Also note that the solutions given here show only one possibility - most of the times there are multiple options to achieve the same end result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 1</summary>\n",
    "    \n",
    "```python\n",
    "data.head(4)\n",
    "data.tail()\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 2</summary>\n",
    "    \n",
    "```python\n",
    "len(data.columns)\n",
    "data.columns[2]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 3</summary>\n",
    "    \n",
    "```python\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        [\"France\", \"Gewürztraminer\", True], \n",
    "        [\"Australia\", \"divers nature\", True], \n",
    "        [\"Israel\", \"hummus\", True], \n",
    "        [\"Iceland\", \"language\", False]\n",
    "    ], \n",
    "    columns=[\"country\", \"awesome because of\", \"been there\"]\n",
    ")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 4</summary>\n",
    "    \n",
    "```python\n",
    "data[[\"AnzahlFall\", \"AnzahlTodesfall\", \"AnzahlGenesen\"]]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 5</summary>\n",
    "    \n",
    "```python\n",
    "data.loc[:, [\"AnzahlFall\", \"AnzahlTodesfall\", \"AnzahlGenesen\"]]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 6</summary>\n",
    "    \n",
    "```python\n",
    "data.iloc[:, [4, 5, 6]]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 7</summary>\n",
    "    \n",
    "```python\n",
    "data[\"Altersgruppe\"].unique()\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 8</summary>\n",
    "    \n",
    "```python\n",
    "len(data[\"Landkreis\"].unique())\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 9</summary>\n",
    "    \n",
    "```python\n",
    "data[data[\"Landkreis\"] == \"SK Berlin Mitte\"]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 10</summary>\n",
    "    \n",
    "```python\n",
    "data[\n",
    "    (data[\"Bundesland\"] == \"Berlin\") & \n",
    "    (data[\"Altersgruppe\"] == \"A35-A59\")\n",
    "]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 11</summary>\n",
    "    \n",
    "Go through _Chapter 5.6._ one more time.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 12</summary>\n",
    "    \n",
    "```python\n",
    "data.groupby('Landkreis')['AnzahlGenesen'].sum()\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 13</summary>\n",
    "    \n",
    "```python\n",
    "data.groupby('Altersgruppe')['AnzahlFall'].sum().plot(\n",
    "    kind='bar', \n",
    "    title=f'Number of COVID-19 cases in Berlin'\n",
    ")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution to final exercise</summary>\n",
    "    \n",
    "```python\n",
    "import datetime\n",
    "vaccination_monitoring = vaccination_monitoring[:-2]\n",
    "vaccination_monitoring = vaccination_monitoring[vaccination_monitoring[\"Datum\"] < datetime.datetime.today()]\n",
    "vaccination_monitoring = vaccination_monitoring.set_index(\"Datum\")\n",
    "vaccination_monitoring.plot();\n",
    "vaccination_monitoring.cumsum().plot();\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
